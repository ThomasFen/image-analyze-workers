/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory();
	else if(typeof define === 'function' && define.amd)
		define([], factory);
	else {
		var a = factory();
		for(var i in a) (typeof exports === 'object' ? exports : root)[i] = a[i];
	}
})(typeof self !== 'undefined' ? self : this, function() {
return /******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "./src/googlemeet-segmentation-tflite-worker-worker.ts":
/*!*************************************************************!*\
  !*** ./src/googlemeet-segmentation-tflite-worker-worker.ts ***!
  \*************************************************************/
/***/ (() => {

eval("\n// import { GoogleMeetSegmentationConfig,  GoogleMeetSegmentationOperationParams,  GoogleMeetSegmentationSmoothingType,  WorkerCommand, WorkerResponse, } from './const'\n// import * as tf from '@tensorflow/tfjs';\n// import { BrowserType } from './BrowserUtil';\n// import {setWasmPath} from '@tensorflow/tfjs-backend-wasm';\n// import { drawArrayToCanvas, imageToGrayScaleArray, padSymmetricImage } from './utils';\n// import { browser } from '@tensorflow/tfjs';\n// const ctx: Worker = self as any  // eslint-disable-line no-restricted-globals\n// let model:tf.GraphModel|null\n// class JBFWasm {\n//     private static _instance:JBFWasm\n//     private constructor(){}\n//     private mod?:any\n//     private sm?:WebAssembly.Memory\n//     srcMemory?:Float32Array \n//     segMemory?:Float32Array \n//     outMemory?:Float32Array\n//     public static async getInstance():Promise<JBFWasm>{\n//         if(!this._instance){\n//             console.log(\"create instance\")\n//             this._instance = new JBFWasm()\n//             const promise = await import(\"../crate/pkg\")\n//             this._instance.mod = await promise['default']\n//             console.log(\"module loeded\",this._instance.mod)\n//             const res = this._instance.mod.get_config()\n//             this._instance.sm = this._instance.mod?.shared_memory() as WebAssembly.Memory\n//             this._instance.srcMemory = new Float32Array(this._instance.sm.buffer, res[0]);\n//             this._instance.segMemory = new Float32Array(this._instance.sm.buffer, res[1]);\n//             this._instance.outMemory = new Float32Array(this._instance.sm.buffer, res[2]);\n//         }\n//         return this._instance\n//     }\n//     doFilter = (w:number, h:number, sp:number, range:number) =>{\n//         this.mod.do_filter(w, h ,sp, range)\n//     }\n// }\n// const load_module = async (config: GoogleMeetSegmentationConfig) => {\n//     console.log(config.browserType)\n//     if(config.useTFWasmBackend || config.browserType === BrowserType.SAFARI){\n//       console.log(\"use cpu backend, wasm doesnot support enough function\")\n//       require('@tensorflow/tfjs-backend-wasm')\n//       setWasmPath(config.wasmPath)\n//       await tf.setBackend(\"wasm\")\n//     //   await tf.setBackend(\"cpu\")\n//     }else{\n//       console.log(\"use webgl backend\")\n//       require('@tensorflow/tfjs-backend-webgl')\n//       try{\n//         await tf.setBackend(\"webgl\")\n//       }catch{\n//         await tf.setBackend(\"cpu\")\n//       }\n//     }\n// }\n// // Case.1 Use ImageBitmap (for Chrome default)\n// //// (1) Only Google Meet Segmentation (not Joint Bilateral Filter)\n// const predict = async (image:ImageBitmap, config: GoogleMeetSegmentationConfig, params: GoogleMeetSegmentationOperationParams):Promise<number[][][]>=> {\n//     const off = new OffscreenCanvas(params.processWidth, params.processHeight)\n//     const ctx = off.getContext(\"2d\")!\n//     ctx.drawImage(image, 0, 0, off.width, off.height)\n//     const imageData = ctx.getImageData(0, 0, off.width, off.height)\n//     let bm:number[][][]|null = null\n//     tf.tidy(()=>{\n//         let tensor = tf.browser.fromPixels(imageData)\n//         tensor = tensor.expandDims(0)\n//         tensor = tf.cast(tensor, 'float32')\n//         tensor = tensor.div(255.0)\n//         let prediction = model!.predict(tensor) as tf.Tensor\n//         prediction = prediction.squeeze()\n//         prediction = prediction.softmax()\n//         let [predTensor0, predTensor1] = tf.split(prediction, 2, 2)\n//         predTensor0 = tf.cast(predTensor0.mul(255),'float32')\n//         bm = predTensor0.arraySync() as number[][][]\n//     }) \n//     return bm!\n// }\n// //// (2) With GPU JBF\n// const matrix_gpu_map:{[key:string]:any} = {}\n// const predict_jbf_gpu = async (image:ImageBitmap, config: GoogleMeetSegmentationConfig, params: GoogleMeetSegmentationOperationParams):Promise<number[][][]>=> {\n//     const off = new OffscreenCanvas(params.processWidth, params.processHeight)\n//     const ctx = off.getContext(\"2d\")!\n//     ctx.drawImage(image, 0, 0, off.width, off.height)\n//     const imageData = ctx.getImageData(0, 0, off.width, off.height)\n//     const spatialKern = params.smoothingS\n//     const rangeKern   = params.smoothingR\n//     if(!matrix_gpu_map[`${params.smoothingR}`]){\n//         const gaussianRange   = 1 / Math.sqrt(2*Math.PI * (rangeKern*rangeKern))\n//         const matrix = (()=>{\n//             const t = tf.tensor1d(Array.from(new Array(256)).map((v,i) => i))\n//             const matrix = t.mul(-1).mul(t).mul(gaussianRange).exp()\n//             return matrix\n//         })()\n//         matrix_gpu_map[`${rangeKern}`] = matrix\n//     }\n//     const matrix = matrix_gpu_map[`${rangeKern}`]\n//     let bm:number[][][]|null = null\n//     tf.tidy(()=>{\n//         let orgTensor = tf.browser.fromPixels(imageData)\n//         const width  = imageData.width\n//         const height = imageData.height\n//         let tensor = orgTensor.expandDims(0)\n//         tensor = tf.cast(tensor, 'float32')\n//         tensor = tensor.div(255.0)\n//         let prediction = model!.predict(tensor) as tf.Tensor\n//         prediction = prediction.squeeze()\n//         prediction = prediction.softmax()\n//         let [predTensor0, predTensor1] = tf.split(prediction, 2, 2)\n//         // ↑ここまで同じ\n//         let newTensor = orgTensor.mean(2).toFloat()\n//         predTensor0 = predTensor0.squeeze()\n//         console.log(\"before\", predTensor0.shape, newTensor.shape)\n//         newTensor   = newTensor.mirrorPad([[spatialKern,spatialKern],[spatialKern,spatialKern]], 'symmetric')\n//         predTensor0 = predTensor0.mirrorPad([[spatialKern,spatialKern],[spatialKern,spatialKern]], 'symmetric')\n//         console.log(\"after\", predTensor0.shape, newTensor.shape)\n//         let outTensor = tf.ones([width, height])\n//         let outvals:tf.Tensor[] = [] \n//         for(let i=spatialKern; i<spatialKern+height; i++){\n//             console.log(\"row:\",i)\n//             for(let j=spatialKern; j<spatialKern+width; j++){\n//                 /// https://github.com/tensorflow/tensorflow/issues/39750\n//                 /// Slice is magnitude slower!!! \n//                 // console.log(i,j)\n//                 // const neighbourhood = (newTensor as tf.Tensor2D).slice([i-spatialKern, j-spatialKern],[2 * spatialKern + 1, 2 * spatialKern + 1])\n//                 // const centerVal = (newTensor as tf.Tensor2D).slice([i,j],[1,1])\n//                 // const indexes = neighbourhood.sub(centerVal).abs().toInt()\n//                 // const res = matrix.gather(indexes)\n//                 // const norm = res.sum()\n//                 // const val = newTensor.slice([i-spatialKern, j-spatialKern],[2 * spatialKern + 1, 2 * spatialKern + 1]).mul(res).sum().div(norm) as tf.Tensor1D\n//                 // //console.log(val)\n//                 // outvals.push(val)\n//                 // neighbourhood.dispose()\n//                 // centerVal.dispose()\n//                 // indexes.dispose()\n//                 // res.dispose\n//                 // norm.dispose()\n//             }\n//         }\n//         console.log(outvals)\n//         console.log(outvals.length)\n//         console.log(outvals[0])\n//         // // const result = tf.concat1d(outvals).reshape([width, height])\n//         // // result.expandDims(2)\n//         // console.log(\"RESULT:!!A\",result)\n//         // console.log(\"RESULT:!!B\",result.shape)\n//         // console.log(\"RESULT:!!C\",result.toString())\n//         // bm = result.arraySync() as number[][][]\n//     }) \n//     return bm!\n// }\n// //// (3) With JS JBF, Only BJF (resize and greyscale, padding are done in gpu)\n// const matrix_js_map:{[key:string]:any} = {}\n// const output_memory_map:{[key:string]:any} = {}\n// const predict_jbf_js = async (image:ImageBitmap, config: GoogleMeetSegmentationConfig, params: GoogleMeetSegmentationOperationParams):Promise<number[][][]>=> {\n//     const off = new OffscreenCanvas(image.width, image.height)\n//     const ctx = off.getContext(\"2d\")!\n//     ctx.drawImage(image, 0, 0, off.width, off.height)\n//     const imageData = ctx.getImageData(0, 0, off.width, off.height)\n//     const spatialKern = params.smoothingS\n//     let seg:number[][]|null = null\n//     let img:number[][]|null = null\n//     tf.tidy(()=>{\n//         let orgTensor = tf.browser.fromPixels(imageData)\n//         let tensor = tf.image.resizeBilinear(orgTensor,[params.processHeight, params.processWidth])\n//         tensor = tensor.expandDims(0)        \n//         tensor = tf.cast(tensor, 'float32')\n//         tensor = tensor.div(255.0)\n//         let prediction = model!.predict(tensor) as tf.Tensor\n//         prediction = prediction.squeeze()\n//         prediction = prediction.softmax()\n//         let [predTensor0, predTensor1] = tf.split(prediction, 2, 2)\n//         orgTensor = tf.image.resizeBilinear(orgTensor, [params.jbfWidth, params.jbfHeight])\n//         predTensor0 = tf.image.resizeBilinear(predTensor0, [params.jbfWidth, params.jbfHeight])\n//         let newTensor = orgTensor.mean(2).toFloat()\n//         predTensor0 = predTensor0.squeeze()\n//         newTensor   = newTensor.mirrorPad([[spatialKern,spatialKern],[spatialKern,spatialKern]], 'symmetric')\n//         predTensor0 = predTensor0.mirrorPad([[spatialKern,spatialKern],[spatialKern,spatialKern]], 'symmetric')        \n//         predTensor0 = predTensor0.squeeze()\n//         predTensor0 = tf.cast(predTensor0.mul(255),'float32')\n//         seg = predTensor0.arraySync() as number[][]\n//         img = newTensor.arraySync()  as number[][]\n//     })\n//     const width  = params.jbfWidth\n//     const height = params.jbfHeight\n//     const matrix_js_map_key = `${params.smoothingR}`\n//     if(!matrix_js_map[matrix_js_map_key]){\n//         const gaussianRange   = 1 / Math.sqrt(2*Math.PI * (params.smoothingR*params.smoothingR))\n//         matrix_js_map[matrix_js_map_key] = Array.from(new Array(256)).map((v,i) => Math.exp(i*i*-1*gaussianRange))\n//         // matrix_js_map[matrix_js_map_key] = Array.from(new Array(256)).map((v,i) => Math.exp(i*i*-1*params.smoothingR))\n//     }\n//     const output_memory_map_key = `${width}x${height}`\n//     if(!output_memory_map[output_memory_map_key] || params.staticMemory === false){\n//         output_memory_map[output_memory_map_key] = Array.from(new Array(height), () => new Array(width).fill(0))\n//     }\n//     const matrix_js = matrix_js_map[matrix_js_map_key]\n//     const result    = output_memory_map[output_memory_map_key]\n//     for(let i=spatialKern; i<spatialKern+height; i++){\n//         for(let j=spatialKern; j<spatialKern+width; j++){\n//             const centerVal = img![i][j]\n//             let norm = 0\n//             let sum  = 0\n//             for(let ki = 0 ; ki < spatialKern*2+1; ki++){\n//                 for(let kj = 0 ; kj < spatialKern*2+1; kj++){\n//                     const index = Math.floor(Math.abs(img![i - spatialKern + ki][j-spatialKern + kj] - centerVal))\n//                     const val = matrix_js[index]\n//                     norm += val\n//                     sum += seg![i - spatialKern + ki][j-spatialKern + kj] * val\n//                 }\n//             }\n//             result[i - spatialKern][j - spatialKern] = sum/norm\n//         }\n//     }\n//     return result\n// }\n// //// (4) With WASM JBF, Only BJF (resize and greyscale, padding are done in gpu)\n// const predict_jbf_wasm = async (image:ImageBitmap, config: GoogleMeetSegmentationConfig, params: GoogleMeetSegmentationOperationParams):Promise<number[][][]>=> {\n//     const jbf = await JBFWasm.getInstance()\n//     const off = new OffscreenCanvas(image.width, image.height)\n//     const ctx = off.getContext(\"2d\")!\n//     ctx.drawImage(image, 0, 0, off.width, off.height)\n//     const imageData = ctx.getImageData(0, 0, off.width, off.height)\n//     const spatialKern = params.smoothingS\n//     let seg:number[][]|null = null\n//     let img:number[][]|null = null\n//     tf.tidy(()=>{\n//         let orgTensor = tf.browser.fromPixels(imageData)\n//         let tensor = tf.image.resizeBilinear(orgTensor,[params.processHeight, params.processWidth])\n//         tensor = tensor.expandDims(0)        \n//         tensor = tf.cast(tensor, 'float32')\n//         tensor = tensor.div(255.0)\n//         let prediction = model!.predict(tensor) as tf.Tensor\n//         prediction = prediction.squeeze()\n//         prediction = prediction.softmax()\n//         let [predTensor0, predTensor1] = tf.split(prediction, 2, 2)\n//         orgTensor = tf.image.resizeBilinear(orgTensor, [params.jbfWidth, params.jbfHeight])\n//         predTensor0 = tf.image.resizeBilinear(predTensor0, [params.jbfWidth, params.jbfHeight])\n//         let newTensor = orgTensor.mean(2).toFloat()\n//         predTensor0 = predTensor0.squeeze()\n//         newTensor   = newTensor.mirrorPad([[spatialKern,spatialKern],[spatialKern,spatialKern]], 'symmetric')\n//         predTensor0 = predTensor0.mirrorPad([[spatialKern,spatialKern],[spatialKern,spatialKern]], 'symmetric')        \n//         predTensor0 = predTensor0.squeeze()\n//         predTensor0 = tf.cast(predTensor0.mul(255),'float32')\n//         newTensor   = tf.cast(newTensor, 'float32')\n//         seg = predTensor0.arraySync() as number[][]\n//         img = newTensor.arraySync()  as number[][]\n//     })\n//     const width  = params.jbfWidth\n//     const height = params.jbfHeight\n//     jbf.srcMemory?.set(img!.flat())\n//     jbf.segMemory?.set(seg!.flat())\n//     const output_memory_map_key = `${width}x${height}`\n//     if(!output_memory_map[output_memory_map_key] || params.staticMemory === false){\n//         output_memory_map[output_memory_map_key] = Array.from(new Array(height), () => new Array(width).fill(0))\n//     }\n//     const result    = output_memory_map[output_memory_map_key]\n//     jbf.doFilter(width, height, spatialKern, params.smoothingR)\n//     for(let i=0; i<height; i++){\n//         for(let j=0; j<width; j++){\n//             result[i][j] = jbf.outMemory![i*width + j]\n//         }\n//     }\n//     return result\n// }\n// //// (5) With JS JBF, JBF and resize and greyscale, padding\n// const segCanvas = new OffscreenCanvas(100,100)\n// const segResizedCanvas = new OffscreenCanvas(100,100)\n// const imgResizedCanvas = new OffscreenCanvas(100,100)\n// const predict_jbf_js_canvas = async (image:ImageBitmap, config: GoogleMeetSegmentationConfig, params: GoogleMeetSegmentationOperationParams):Promise<number[][][]>=> {\n//     const off = new OffscreenCanvas(params.processWidth, params.processHeight)\n//     const ctx = off.getContext(\"2d\")!\n//     ctx.drawImage(image, 0, 0, off.width, off.height)\n//     const imageData = ctx.getImageData(0, 0, off.width, off.height)\n//     const spatialKern = params.smoothingS\n//     let seg:number[][]|null = null\n//     let img:number[][]|null = null\n//     tf.tidy(()=>{\n//         let orgTensor = tf.browser.fromPixels(imageData)\n//         // let tensor = tf.image.resizeBilinear(orgTensor,[params.processHeight, params.processWidth])\n//         let tensor = orgTensor.expandDims(0)        \n//         tensor = tf.cast(tensor, 'float32')\n//         tensor = tensor.div(255.0)\n//         let prediction = model!.predict(tensor) as tf.Tensor\n//         prediction = prediction.squeeze()\n//         prediction = prediction.softmax()\n//         let [predTensor0, predTensor1] = tf.split(prediction, 2, 2)\n//         predTensor0 = predTensor0.squeeze()\n//         seg = predTensor0.arraySync() as number[][]\n//     })\n//     const width  = params.jbfWidth\n//     const height = params.jbfHeight\n//     drawArrayToCanvas(seg!, segCanvas)\n//     segResizedCanvas.width  = width\n//     segResizedCanvas.height = height\n//     const segCtx = segResizedCanvas.getContext(\"2d\")!\n//     // segCtx.imageSmoothingEnabled = true;\n//     // segCtx.imageSmoothingQuality = \"low\"\n//     // //@ts-ignore\n//     // segCtx.mozImageSmoothingEnabled = true;\n//     // //@ts-ignore\n//     // segCtx.webkitImageSmoothingEnabled = true;\n//     // //@ts-ignore\n//     // segCtx.msImageSmoothingEnabled = true;\n//     segCtx.drawImage(segCanvas, 0, 0, width, height)\n//     const segImg = segCtx.getImageData(0, 0, width, height)\n//     seg = imageToGrayScaleArray(segImg)\n//     seg = padSymmetricImage(seg, spatialKern, spatialKern, spatialKern, spatialKern)\n//     imgResizedCanvas.width  = width\n//     imgResizedCanvas.height = height\n//     const imgCtx = segResizedCanvas.getContext(\"2d\")!\n//     imgCtx.drawImage(image, 0, 0, width, height)\n//     const imgImg = imgCtx.getImageData(0, 0, width, height)\n//     img = imageToGrayScaleArray(imgImg)\n//     img = padSymmetricImage(img, spatialKern, spatialKern, spatialKern, spatialKern)\n//     const matrix_js_map_key = `${params.smoothingR}`\n//     if(!matrix_js_map[matrix_js_map_key]){\n//         const gaussianRange   = 1 / Math.sqrt(2*Math.PI * (params.smoothingR*params.smoothingR))\n//         matrix_js_map[matrix_js_map_key] = Array.from(new Array(256)).map((v,i) => Math.exp(i*i*-1*gaussianRange))\n//     }\n//     const matrix_js = matrix_js_map[`${params.smoothingR}`]\n//     const result = Array.from(new Array(height), () => new Array(width).fill(0));\n//     for(let i=spatialKern; i<spatialKern+height; i++){\n//         for(let j=spatialKern; j<spatialKern+width; j++){\n//             const centerVal = img![i][j]\n//             let norm = 0\n//             let sum  = 0\n//             for(let ki = 0 ; ki < spatialKern*2+1; ki++){\n//                 for(let kj = 0 ; kj < spatialKern*2+1; kj++){\n//                     const index = Math.floor(Math.abs(img![i - spatialKern + ki][j-spatialKern + kj] - centerVal))\n//                     const val = matrix_js[index]\n//                     norm += val\n//                     sum += seg![i - spatialKern + ki][j-spatialKern + kj] * val\n//                 }\n//             }\n//             result[i - spatialKern][j - spatialKern] = sum/norm\n//         }\n//     }\n//     return result\n// }\n// // Case.2 Use ImageBitmap (for Safari or special intent)\n// //// (1) \n// const predictWithData = async (data: Uint8ClampedArray , config: GoogleMeetSegmentationConfig, params: GoogleMeetSegmentationOperationParams):Promise<number[][][]> => {\n//     // const imageData = new ImageData(data, params.processWidth, params.processHeight)\n//     const imageData = new ImageData(data, params.originalWidth, params.originalHeight)\n//     let bm:number[][][]|null = null\n//     tf.tidy(()=>{\n//         let tensor = tf.browser.fromPixels(imageData)\n//         tensor = tf.image.resizeBilinear(tensor,[params.processHeight, params.processWidth])\n//         tensor = tensor.expandDims(0)\n//         tensor = tf.cast(tensor, 'float32')\n//         tensor = tensor.div(255.0)\n//         let prediction = model!.predict(tensor) as tf.Tensor\n//         prediction = prediction.softmax()\n//         prediction = prediction.squeeze()\n//         let [predTensor0, predTensor1] = tf.split(prediction, 2, 2)\n//         predTensor0 = predTensor0.squeeze()\n//         predTensor0 = tf.cast(predTensor0.mul(255),'float32')\n//         bm = predTensor0.arraySync() as number[][][]\n//    })\n//     return bm!\n// }\n// // //// (2) not implement\n// // //// (3) With JS JBF, Only BJF (resize and greyscale, padding are done in gpu)\n// const predict_jbf_js_WithData = async (data: Uint8ClampedArray, config: GoogleMeetSegmentationConfig, params: GoogleMeetSegmentationOperationParams):Promise<number[][][]>=> {\n//     const imageData = new ImageData(data, params.originalWidth, params.originalHeight)\n//     const spatialKern = params.smoothingS\n//     let seg:number[][]|null = null\n//     let img:number[][]|null = null\n//     tf.tidy(()=>{\n//         let orgTensor = tf.browser.fromPixels(imageData)\n//         let tensor = tf.image.resizeBilinear(orgTensor,[params.processHeight, params.processWidth])\n//         tensor = tensor.expandDims(0)        \n//         tensor = tf.cast(tensor, 'float32')\n//         tensor = tensor.div(255.0)\n//         let prediction = model!.predict(tensor) as tf.Tensor\n//         prediction = prediction.squeeze()\n//         prediction = prediction.softmax()\n//         let [predTensor0, predTensor1] = tf.split(prediction, 2, 2)\n//         orgTensor = tf.image.resizeBilinear(orgTensor, [params.jbfWidth, params.jbfHeight])\n//         predTensor0 = tf.image.resizeBilinear(predTensor0, [params.jbfWidth, params.jbfHeight])\n//         let newTensor = orgTensor.mean(2).toFloat()\n//         predTensor0 = predTensor0.squeeze()\n//         newTensor   = newTensor.mirrorPad([[spatialKern,spatialKern],[spatialKern,spatialKern]], 'symmetric')\n//         predTensor0 = predTensor0.mirrorPad([[spatialKern,spatialKern],[spatialKern,spatialKern]], 'symmetric')        \n//         predTensor0 = predTensor0.squeeze()\n//         predTensor0 = tf.cast(predTensor0.mul(255),'float32')\n//         seg = predTensor0.arraySync() as number[][]\n//         img = newTensor.arraySync()  as number[][]\n//     })\n//     const width  = params.jbfWidth\n//     const height = params.jbfHeight\n//     const matrix_js_map_key = `${params.smoothingR}`\n//     if(!matrix_js_map[matrix_js_map_key]){\n//         const gaussianRange   = 1 / Math.sqrt(2*Math.PI * (params.smoothingR*params.smoothingR))\n//         matrix_js_map[matrix_js_map_key] = Array.from(new Array(256)).map((v,i) => Math.exp(i*i*-1*gaussianRange))\n//         // matrix_js_map[matrix_js_map_key] = Array.from(new Array(256)).map((v,i) => Math.exp(i*i*-1*params.smoothingR))\n//     }\n//     const output_memory_map_key = `${width}x${height}`\n//     if(!output_memory_map[output_memory_map_key] || params.staticMemory === false){\n//         output_memory_map[output_memory_map_key] = Array.from(new Array(height), () => new Array(width).fill(0))\n//     }\n//     const matrix_js = matrix_js_map[matrix_js_map_key]\n//     const result    = output_memory_map[output_memory_map_key]\n//     for(let i=spatialKern; i<spatialKern+height; i++){\n//         for(let j=spatialKern; j<spatialKern+width; j++){\n//             const centerVal = img![i][j]\n//             let norm = 0\n//             let sum  = 0\n//             for(let ki = 0 ; ki < spatialKern*2+1; ki++){\n//                 for(let kj = 0 ; kj < spatialKern*2+1; kj++){\n//                     const index = Math.floor(Math.abs(img![i - spatialKern + ki][j-spatialKern + kj] - centerVal))\n//                     const val = matrix_js[index]\n//                     norm += val\n//                     sum += seg![i - spatialKern + ki][j-spatialKern + kj] * val\n//                 }\n//             }\n//             result[i - spatialKern][j - spatialKern] = sum/norm\n//         }\n//     }\n//     return result\n// }\n// //// (4) With WASM JBF, Only BJF (resize and greyscale, padding are done in gpu)\n// const predict_jbf_wasm_WithData = async (data: Uint8ClampedArray, config: GoogleMeetSegmentationConfig, params: GoogleMeetSegmentationOperationParams):Promise<number[][][]>=> {\n//     const jbf = await JBFWasm.getInstance()\n//     const imageData = new ImageData(data, params.originalWidth, params.originalHeight)\n//     const spatialKern = params.smoothingS\n//     let seg:number[][]|null = null\n//     let img:number[][]|null = null\n//     tf.tidy(()=>{\n//         let orgTensor = tf.browser.fromPixels(imageData)\n//         let tensor = tf.image.resizeBilinear(orgTensor,[params.processHeight, params.processWidth])\n//         tensor = tensor.expandDims(0)        \n//         tensor = tf.cast(tensor, 'float32')\n//         tensor = tensor.div(255.0)\n//         let prediction = model!.predict(tensor) as tf.Tensor\n//         prediction = prediction.squeeze()\n//         prediction = prediction.softmax()\n//         let [predTensor0, predTensor1] = tf.split(prediction, 2, 2)\n//         orgTensor = tf.image.resizeBilinear(orgTensor, [params.jbfWidth, params.jbfHeight])\n//         predTensor0 = tf.image.resizeBilinear(predTensor0, [params.jbfWidth, params.jbfHeight])\n//         let newTensor = orgTensor.mean(2).toFloat()\n//         predTensor0 = predTensor0.squeeze()\n//         newTensor   = newTensor.mirrorPad([[spatialKern,spatialKern],[spatialKern,spatialKern]], 'symmetric')\n//         predTensor0 = predTensor0.mirrorPad([[spatialKern,spatialKern],[spatialKern,spatialKern]], 'symmetric')        \n//         predTensor0 = predTensor0.squeeze()\n//         predTensor0 = tf.cast(predTensor0.mul(255),'float32')\n//         newTensor   = tf.cast(newTensor, 'float32')\n//         seg = predTensor0.arraySync() as number[][]\n//         img = newTensor.arraySync()  as number[][]\n//     })\n//     const width  = params.jbfWidth\n//     const height = params.jbfHeight\n//     jbf.srcMemory?.set(img!.flat())\n//     jbf.segMemory?.set(seg!.flat())\n//     const output_memory_map_key = `${width}x${height}`\n//     if(!output_memory_map[output_memory_map_key] || params.staticMemory === false){\n//         output_memory_map[output_memory_map_key] = Array.from(new Array(height), () => new Array(width).fill(0))\n//     }\n//     const result    = output_memory_map[output_memory_map_key]\n//     jbf.doFilter(width, height, spatialKern, params.smoothingR)\n//     for(let i=0; i<height; i++){\n//         for(let j=0; j<width; j++){\n//             result[i][j] = jbf.outMemory![i*width + j]\n//         }\n//     }\n//     return result\n// }\n// //// (5) With JS JBF, JBF and resize and greyscale, padding\n// // Not implement. resize function is not implemented without Canvas\n// onmessage = async (event) => {\n//     if (event.data.message === WorkerCommand.INITIALIZE) {\n//         const config = event.data.config as GoogleMeetSegmentationConfig\n//         await load_module(config)\n//         tf.ready().then(async()=>{\n//             tf.env().set('WEBGL_CPU_FORWARD', false)\n//             model = await tf.loadGraphModel(config.modelPath)\n//             console.log(model.inputs)\n//             console.log(model.inputNodes)\n//             console.log(model.outputs)\n//             console.log(model.outputNodes)\n//             ctx.postMessage({ message: WorkerResponse.INITIALIZED})\n//         })\n//     } else if (event.data.message === WorkerCommand.PREDICT) {\n//         //    console.log(\"requested predict bodypix.\")\n//         const image: ImageBitmap = event.data.image\n//         const data = event.data.data\n//         const config: GoogleMeetSegmentationConfig = event.data.config\n//         const params: GoogleMeetSegmentationOperationParams = event.data.params\n//         const uid: number = event.data.uid\n//         console.log(\"current backend[worker thread]:\",tf.getBackend())\n//         if(data){ // Case.2\n//             if(params.smoothingS == 0 && params.smoothingR == 0){\n//                 const prediction  = await predictWithData(data, config, params)\n//                 ctx.postMessage({ message: WorkerResponse.PREDICTED, uid: uid, prediction: prediction })\n//             }else{\n//                 let prediction\n//                 switch(params.smoothingType){\n//                     case GoogleMeetSegmentationSmoothingType.JS:\n//                         prediction = await predict_jbf_js_WithData(data, config, params)\n//                         break\n//                     case GoogleMeetSegmentationSmoothingType.WASM:\n//                         prediction = await predict_jbf_wasm_WithData(data, config, params)\n//                         break\n//                     case GoogleMeetSegmentationSmoothingType.JS_CANVAS:\n//                         console.log(\"not support smoothing type\", \"JS_CANVAS\")\n//                         prediction = await predict_jbf_js_WithData(data, config, params)\n//                         break\n//                 }\n//                 ctx.postMessage({ message: WorkerResponse.PREDICTED, uid: uid, prediction: prediction })\n//             }\n//         }else{ // Case.1\n//             if(params.smoothingS == 0 && params.smoothingR == 0){\n//                 const prediction = await predict(image, config, params)\n//                 ctx.postMessage({ message: WorkerResponse.PREDICTED, uid: uid, prediction: prediction })\n//             }else{\n//                 let prediction\n//                 switch(params.smoothingType){\n//                     case GoogleMeetSegmentationSmoothingType.JS:\n//                         prediction = await predict_jbf_js(image, config, params)\n//                         break\n//                     case GoogleMeetSegmentationSmoothingType.WASM:\n//                         prediction = await predict_jbf_wasm(image, config, params)\n//                         break\n//                     case GoogleMeetSegmentationSmoothingType.GPU:\n//                         prediction = await predict_jbf_gpu(image, config, params)\n//                         break\n//                     case GoogleMeetSegmentationSmoothingType.JS_CANVAS:\n//                         prediction = await predict_jbf_js_canvas(image, config, params)\n//                         break\n//                 }\n//                 ctx.postMessage({ message: WorkerResponse.PREDICTED, uid: uid, prediction: prediction })\n//             }\n//         }\n//     }\n// }\n\n\n//# sourceURL=webpack://@dannadori/googlemeet-segmentation-tflite-worker-js/./src/googlemeet-segmentation-tflite-worker-worker.ts?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = {};
/******/ 	__webpack_modules__["./src/googlemeet-segmentation-tflite-worker-worker.ts"]();
/******/ 	
/******/ 	return __webpack_exports__;
/******/ })()
;
});